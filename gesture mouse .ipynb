{"cells":[{"cell_type":"code","execution_count":1,"id":"0692feed","metadata":{"id":"0692feed","executionInfo":{"status":"error","timestamp":1640231853652,"user_tz":-330,"elapsed":1608,"user":{"displayName":"GOKULSARVESH S K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjbro1oe0xbSD7QH7PTbv5urLEZgkAtMwigdguB3Q=s64","userId":"16868546445702885019"}},"outputId":"3d8e331a-f513-4a90-b6e9-7db352706eb3","colab":{"base_uri":"https://localhost:8080/","height":373}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d10f27909f52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import cv2\n","import mediapipe\n","import numpy\n","import autopy\n","\n","cap = cv2.VideoCapture(0)\n","initHand = mediapipe.solutions.hands  # Initializing mediapipe\n","# Object of mediapipe with \"arguments for the hands module\"\n","mainHand = initHand.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.8)\n","draw = mediapipe.solutions.drawing_utils  # Object to draw the connections between each finger index\n","wScr, hScr = autopy.screen.size()  # Outputs the high and width of the screen (1920 x 1080)\n","pX, pY = 0, 0  # Previous x and y location\n","cX, cY = 0, 0  # Current x and y location\n","\n","\n","def handLandmarks(colorImg):\n","    landmarkList = []  # Default values if no landmarks are tracked\n","\n","    landmarkPositions = mainHand.process(colorImg)  # Object for processing the video input\n","    landmarkCheck = landmarkPositions.multi_hand_landmarks  # Stores the out of the processing object (returns False on empty)\n","    if landmarkCheck:  # Checks if landmarks are tracked\n","        for hand in landmarkCheck:  # Landmarks for each hand\n","            for index, landmark in enumerate(hand.landmark):  # Loops through the 21 indexes and outputs their landmark coordinates (x, y, & z)\n","                draw.draw_landmarks(img, hand, initHand.HAND_CONNECTIONS)  # Draws each individual index on the hand with connections\n","                h, w, c = img.shape  # Height, width and channel on the image\n","                centerX, centerY = int(landmark.x * w), int(landmark.y * h)  # Converts the decimal coordinates relative to the image for each index\n","                landmarkList.append([index, centerX, centerY])  # Adding index and its coordinates to a list\n","                \n","    return landmarkList\n","\n","\n","def fingers(landmarks):\n","    fingerTips = []  # To store 4 sets of 1s or 0s\n","    tipIds = [4, 8, 12, 16, 20]  # Indexes for the tips of each finger\n","    \n","    # Check if thumb is up\n","    if landmarks[tipIds[0]][1] > lmList[tipIds[0] - 1][1]:\n","        fingerTips.append(1)\n","    else:\n","        fingerTips.append(0)\n","    \n","    # Check if fingers are up except the thumb\n","    for id in range(1, 5):\n","        if landmarks[tipIds[id]][2] < landmarks[tipIds[id] - 3][2]:  # Checks to see if the tip of the finger is higher than the joint\n","            fingerTips.append(1)\n","        else:\n","            fingerTips.append(0)\n","\n","    return fingerTips\n","\n","\n","while True:\n","    check, img = cap.read()  # Reads frames from the camera\n","    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Changes the format of the frames from BGR to RGB\n","    lmList = handLandmarks(imgRGB)\n","    # cv2.rectangle(img, (75, 75), (640 - 75, 480 - 75), (255, 0, 255), 2)\n","    \n","    if len(lmList) != 0:\n","        x1, y1 = lmList[8][1:]  # Gets index 8s x and y values (skips index value because it starts from 1)\n","        x2, y2 = lmList[12][1:]  # Gets index 12s x and y values (skips index value because it starts from 1)\n","        finger = fingers(lmList)  # Calling the fingers function to check which fingers are up\n","        \n","        if finger[1] == 1 and finger[2] == 0:  # Checks to see if the pointing finger is up and thumb finger is down\n","            x3 = numpy.interp(x1, (75, 640 - 75), (0, wScr))  # Converts the width of the window relative to the screen width\n","            y3 = numpy.interp(y1, (75, 480 - 75), (0, hScr))  # Converts the height of the window relative to the screen height\n","            \n","            cX = pX + (x3 - pX) / 7  # Stores previous x locations to update current x location\n","            cY = pY + (y3 - pY) / 7  # Stores previous y locations to update current y location\n","            \n","            autopy.mouse.move(wScr-cX, cY)  # Function to move the mouse to the x3 and y3 values (wSrc inverts the direction)\n","            pX, pY = cX, cY  # Stores the current x and y location as previous x and y location for next loop\n","\n","        if finger[1] == 0 and finger[0] == 1:  # Checks to see if the pointer finger is down and thumb finger is up\n","            autopy.mouse.click()  # Left click\n","            \n","    cv2.imshow(\"Webcam\", img)\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break"]},{"cell_type":"code","execution_count":null,"id":"6cffc6a7","metadata":{"id":"6cffc6a7"},"outputs":[],"source":["import mediapipe as mp\n","import cv2\n","import numpy as np\n","import uuid\n","import os\n","mp_drawing = mp.solutions.drawing_utils\n","mp_hands = mp.solutions.hands\n","cap = cv2.VideoCapture(0)\n","\n","with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        \n","        # BGR 2 RGB\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        \n","        # Flip on horizontal\n","        image = cv2.flip(image, 1)\n","        \n","        # Set flag\n","        image.flags.writeable = False\n","        \n","        # Detections\n","        results = hands.process(image)\n","        \n","        # Set flag to true\n","        image.flags.writeable = True\n","        \n","        # RGB 2 BGR\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        print(results)\n","        \n","        # Rendering results\n","        if results.multi_hand_landmarks:\n","            for num, hand in enumerate(results.multi_hand_landmarks):\n","                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n","                                        mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n","                                        mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n","                                         )\n","            \n","        \n","        cv2.imshow('Hand Tracking', image)\n","\n","        if cv2.waitKey(10) & 0xFF == ord('q'):\n","            break\n","\n","cap.release()\n","cv2.destroyAllWindows()\n","mp_drawing.DrawingSpec()\n","os.mkdir('Output Images')\n","cap = cv2.VideoCapture(0)\n","\n","with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        \n","        # BGR 2 RGB\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        \n","        # Flip on horizontal\n","        image = cv2.flip(image, 1)\n","        \n","        # Set flag\n","        image.flags.writeable = False\n","        \n","        # Detections\n","        results = hands.process(image)\n","        \n","        # Set flag to true\n","        image.flags.writeable = True\n","        \n","        # RGB 2 BGR\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        \n","        # Detections\n","        print(results)\n","\t\t  # Rendering results\n","        if results.multi_hand_landmarks:\n","            for num, hand in enumerate(results.multi_hand_landmarks):\n","                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n","                                        mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n","                                        mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n","                                         )\n","            \n","        # Save our image    \n","        cv2.imwrite(os.path.join('Output Images', '{}.jpg'.format(uuid.uuid1())), image)\n","        cv2.imshow('Hand Tracking', image)\n","\n","        if cv2.waitKey(10) & 0xFF == ord('q'):\n","            break\n","\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"id":"8394fd4b","metadata":{"id":"8394fd4b"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"colab":{"name":"gesture mouse .ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}